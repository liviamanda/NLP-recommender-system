{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Final Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team Members**  :\n",
    "- Livia Amanda Annafiah\n",
    "- Alfarabi\n",
    "- Badriah Nursakinah\n",
    "\n",
    "**Dataset**       : [Airline Reviews](https://www.kaggle.com/datasets/juhibhojani/airline-reviews/data)  \n",
    "\n",
    "**Hugging Face**  : [Link](https://huggingface.co/spaces/liviamanda/FlightBuddy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem Statement**  \n",
    "\n",
    "Choosing the right airline can greatly affect a traveler's overall experience, including comfort, service quality, and in-flight amenities. With many online reviews available, airline passengers often **rely on these reviews** to make informed decisions about which airline to choose. However, the large number of reviews can make it difficult and **time-consuming** to read through and understand the general opinion about an airline.\n",
    "\n",
    "**FlightBuddy** aims to solve this problem by using advanced Natural Language Processing (NLP) techniques to analyze airline reviews quickly and accurately. By processing and understanding a large number of reviews, FlightBuddy can determine whether the opinions in the reviews are positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Objective**  \n",
    "\n",
    "The main goal of **FlightBuddy** is to improve the decision-making process for travelers by providing personalized airline recommendations based on the analysis of review sentiments. Specifically, FlightBuddy aims to:\n",
    "\n",
    "- Analyze the sentiment of airline reviews to classify them as positive or negative, with accuracy serving as the metric.\n",
    "- Recommend five airlines with similar positive characteristics for users who have seen favorable reviews.\n",
    "- Suggest top-rated alternative airlines for users who have encountered negative experiences, ensuring they have better options for future travel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This notebook focuses on testing the NLP model using new, unseen data.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B. Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following libraries are used for this inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\septi\\anaconda3\\envs\\hacktive\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\septi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\septi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data loading and manipulation\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Libraries for pre-processing\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Import library to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, module='tensorflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C. Data Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is stored within a compressed zip file, so it must be extracted first before use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\septi\\anaconda3\\envs\\hacktive\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\septi\\anaconda3\\envs\\hacktive\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:1113: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define path to zip file\n",
    "zip_file_path = 'model_logreg.zip'\n",
    "\n",
    "# Read the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    \n",
    "    # Extract all contents to a directory named 'unzipped_model'\n",
    "    zip_ref.extractall('unzipped_model')\n",
    "\n",
    "# Load the model from the unzipped folder\n",
    "unzipped_model_path = os.path.join('unzipped_model', 'model_logreg')\n",
    "model = load_model(unzipped_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is successfully loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, new data will be generated specifically for testing the model. As part of this analysis, two rows are created to represent two reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First, I got delayed and after I waited for al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The flight experience was excellent! The staff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  First, I got delayed and after I waited for al...\n",
       "1  The flight experience was excellent! The staff..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new data\n",
    "df_inf = {'Review': [\"First, I got delayed and after I waited for almost an hour, the flight got cancelled last minute.\",\n",
    "                     \"The flight experience was excellent! The staff were friendly, and everything was smooth.\"]}\n",
    "\n",
    "# Convert to dataframe\n",
    "df_inf = pd.DataFrame(df_inf)\n",
    "\n",
    "# Show data\n",
    "df_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **D. Text Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on to the prediction phase, it's essential to preprocess the data just as it was done in the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "stpwds_id = list(set(stopwords.words('english')))\n",
    "\n",
    "# Add custom stopwords\n",
    "custom_stopwords = ['the', 'to', 'and', 'I', 'was', 'a', 'in', 'of', ' for', 'on', 'flight', 'with', 'that', 'my', 'is', 'not', 'were', 'they',\n",
    "                    'The', 'at', 'we', 'had', 'from', 'but', 'have', 'it', 'this', 'no', 'as', 'me', 'you', 'our', 'be', 'are', 'an', 'very', 'so',\n",
    "                    'service', 'their', 'We', 'time','airline', 'would', 'or', 'us', 'by', 'only', 'get', 'all' 'which']\n",
    "\n",
    "stpwds_id.extend(custom_stopwords)\n",
    "\n",
    "# Define Stemming\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for text preprocessing\n",
    "def text_preprocessing(text):\n",
    "    # Case folding\n",
    "    text = text.lower()\n",
    "\n",
    "    # Mention removal\n",
    "    text = re.sub(r'https?://(?:www\\.[^\\s\\n\\r]+|[^\\s\\n\\r]+)', '', text)\n",
    "\n",
    "    # Hashtags removal\n",
    "    text = re.sub(r'#', '', text)\n",
    "\n",
    "    # Newline removal (\\n)\n",
    "    text = re.sub(r'[\\n\\r]', '', text)\n",
    "\n",
    "    # Replaces the numbers with an empty string\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Whitespace removal\n",
    "    text = text.strip()\n",
    "\n",
    "    # URL removal\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"www.\\S+\", \" \", text)\n",
    "\n",
    "    # Non-letter removal (such as emoticon, symbol (like μ, $, 兀), etc.)\n",
    "    text = re.sub(\"[^A-Za-z\\s']\", \" \", text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Stopwords removal\n",
    "    tokens = [word for word in tokens if word not in stpwds_id]\n",
    "\n",
    "    # Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # Combining Tokens\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the functions for data preprocessing have been defined, they are applied to the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Processed Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First, I got delayed and after I waited for al...</td>\n",
       "      <td>first got delay wait almost hour got cancel la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The flight experience was excellent! The staff...</td>\n",
       "      <td>experi excel staff friendli everyth smooth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  First, I got delayed and after I waited for al...   \n",
       "1  The flight experience was excellent! The staff...   \n",
       "\n",
       "                                    Processed Review  \n",
       "0  first got delay wait almost hour got cancel la...  \n",
       "1         experi excel staff friendli everyth smooth  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Text Preprocessing to the Dataset\n",
    "df_inf['Processed Review'] = df_inf['Review'].apply(lambda x: text_preprocessing(x))\n",
    "\n",
    "# Show before and after processing\n",
    "df_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing has been successfully completed, as seen by the before and after states of the data in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **E. Model Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been preprocessed, the loaded model can be used for prediction to determine whether the review is positive (recommended) or negative (not recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 389ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9634347, 0.0361073],\n",
       "       [0.2070894, 0.8019827]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction array\n",
    "model.predict(df_inf['Processed Review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array represents the model's predictions for two reviews. Each row corresponds to a review, and the two columns represent the probabilities assigned to each class (0 and 1, in this case, representing `Not Recommended` and `Recommended` respectively).\n",
    "\n",
    "- **First review**:\n",
    "  - The model predicts `Not Recommended` with a probability of approximately 0.963.\n",
    "  - The model predicts `Recommended` with a probability of approximately 0.036.\n",
    "\n",
    "- **Second review**:\n",
    "  - The model predicts `Not Recommended` with a probability of approximately 0.207.\n",
    "  - The model predicts `Recommended` with a probability of approximately 0.802."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Not Recommended\n",
      "Recommended\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the trained model\n",
    "y_pred_inf = model.predict(df_inf['Processed Review'])\n",
    "\n",
    "# Loop through each prediction result\n",
    "for pred in y_pred_inf:\n",
    "    \n",
    "    # Get the index of the highest predicted value (argmax)\n",
    "    pred_label = np.argmax(pred)\n",
    "    \n",
    "    # Check the predicted label and print the corresponding recommendation\n",
    "    if pred_label == 0:\n",
    "        print(f'Not Recommended')\n",
    "    elif pred_label == 1:\n",
    "        print(f'Recommended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses the loaded model to predict the recommendation status of pre-processed reviews. The model takes these reviews as input and generates predictions, determining whether each one is `Recommended` or `Not Recommended`. It uses a decision threshold, set at 0.5, to classify reviews. Probabilities higher than this threshold are labeled as `Recommended`, while those falling below are labeled as `Not Recommended`.\n",
    "\n",
    "Therefore, the first review is predicted as `Recommended`, while the second review is predicted as `Recommended`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **F. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the model demonstrates its ability to **successfully** predict unseen data. It can differentiate between **positive (recommended)** and **negative (not recommended)** reviews with accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacktive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
